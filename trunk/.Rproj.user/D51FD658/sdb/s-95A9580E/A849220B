{
    "collab_server" : "",
    "contents" : "# 27/07/2016 script to open and explore the abundance data from Buoy3\n# Alberto.Rovellini@vuw.ac.nz\n\n# 02.08.2016 script reads from .csv because .xlsx is very messy. Goal now is to analyse a bit better the available\n# data, such as the most abundant species and so on, limit the analysis to those species.\n\n# 08.08.2016\n# script calculates correctly the grand mean (i.e. mean of the quadrats and then mean of the three sites),\n# and also the grand standard deviation. Uncertainty is very broad among quadrats and sites. Quadrats are\n# 1 m2 and they are fixed, thus it's possible to see trends one by one in time.\n\n# main issue is that approximate identification and in any case high disaggregation leave me with little\n# information. Best way to proceed is to find a list of species that make up for the greatest bulk of the\n# dataset (say 90% of the numbers) and lump those into heterotrophic/phototrophic. James has to do this as\n# I don't know jack about sponges.\n\n# Interpretation is difficult with so many entries bu the global trends reveal poor sampling in my opinion.\n# Best way to carry on is to take the most abundant species on average and lump them at the end, as opposite \n# to do it from early on. So analyse the final dataframe to get the most abundant entries per year (up to 90%)\n\nrequire(abind)\nrequire(plyr)\nrequire(ggplot2)\nrequire(reshape2)\n\ndataAllYears <- read.csv(\"//Staff/Home/SCIFAC/rovellal/DocumentsRedir/Data/Hoga/buoy3/spongeAbundanceQuadrats.csv\")\n\n# set flags\n\nflagRoutine <- \"average\" # can be either \"sum\" to add the 5 quadrats up, or any other string to take average and sd\n\n# initiate information about the dataset\n\nspecies <- read.csv(\"//Staff/Home/SCIFAC/rovellal/DocumentsRedir/Data/Hoga/buoy3/speciesKey.csv\")\nspecies[species==\"\" | species==0] <- NA # drop all that is not a name, to be refined though\n\n# option 1: keep only the species (or at least what is close)\n\nidentified <- species[,-ncol(species)]\nidentified <- identified[complete.cases(identified),]\n\n# option 2: use species when available and description otherwise\n\nspeciesOrDescription <- list()\n\nfor (i in 1:nrow(species)) {\n  if (is.na(species[,2][i])==T) {\n    speciesOrDescription[[i]] <- species[,3][i]\n  } else {\n    speciesOrDescription[[i]] <- species[,2][i]\n  }\n}\nspeciesOrDescription <- unlist(speciesOrDescription) #\n\n# follows general information about the dataset, such as number of years, quadrats, sites and so on\n\nyears <- levels(factor(substr(names(dataAllYears[-1]),2,3)))\nquadrats <- as.numeric(levels(factor(substr(names(dataAllYears), nchar(names(dataAllYears)), nchar(names(dataAllYears))))))\nquadrats <- quadrats[is.na(quadrats)==F]# number of quadrats per site\ndataColumns <- ncol(dataAllYears)-1 # number of quadrats in all sites in all years, effectivelty number of columns in the frame\nsites <- c(\"A\", \"B\", \"C\")\n\n# each data column is a quadrat. There are five quadrats per site. first letter of the header is X because \n# read.csv() (and read.table() for that matter) do not allow a column name to start wit a number. \n# first 2 digits after X are the year (05 to 16). S is site, and second to last letter (A, B or C) is the site code.\n# final digit is the quadrat within the site.\n\n\n# all the columns need to be turned to numeric. some typos in the excel spreadsheet might cause the columns to be\n# factors or characters. as the method removes everything that cannot be coerced to numeric, typos such as \"19'\"\n# will also be dropped, hence it's recommended to take a look at the data first.\n# in an ideal world I will adapt the script to skim through typos the right way\n\n# cut the whole thing to the first 125 rows, as below that it gets confused\n\ndataAllYears <- dataAllYears[1:124,]\n\n# gets rid of zeros as characters in the datasets\n\nfor (i in 1:ncol(dataAllYears)) {\n  if (is.numeric(dataAllYears[,i])==T) {\n    dataAllYears[,i] <- dataAllYears[,i]\n  } else {\n    dataAllYears[,i] <- as.numeric(levels(dataAllYears[,i])[dataAllYears[,i]]) # this removes everything that won't fit as numeric\n  }\n}\n\ndataAllYears[is.na(dataAllYears)] <- 0 # turns NAs to zeroes\n\n# gets rid of the X in front of the column names because it bothers me. but then again it puts it back\n\ncolnames(dataAllYears) <- c(names(dataAllYears)[1],\n                                  substr(names(dataAllYears[,-1]), 2, nchar(names(dataAllYears[,-1]))))\n\n# yet another strategy, STOLEN from SO\n\ndataAllYears <- dataAllYears[,-1]\n\n# please understand and rename\n\nn <- 1:ncol(dataAllYears)\nind <- data.frame(matrix(c(n, rep(NA, 5 - ncol(dataAllYears)%%5)), byrow=F, nrow = 5))\nnonna <- sapply(ind, function(x) all(!is.na(x)))\nind <- ind[, nonna]\n\n# if statement to decide whether we want to add the quadrats or take their average\n\nif (flagRoutine == \"sum\") {\n  electedFunction <- function(i)rowSums(dataAllYears[,i])\n} else {\n  electedFunction <- function(i) {\n    meanColumn <- rowMeans(dataAllYears[,i])\n    varColumn <- apply(dataAllYears[,i], 1, sd)\n    cbind(meanColumn, (varColumn)^2) # to get the variance, used for the propagation\n  }\n}\n\nsitesFrame <- as.data.frame(do.call(cbind, lapply(ind, electedFunction))) # hahah nailed it\nsitesFrame$Species <- speciesOrDescription\n\n# reorganize the dataframe with first the means and then the sd\n\nsitesFrame <- cbind(sitesFrame[,grepl(\"mean\", names(sitesFrame))], \n                    sitesFrame[,grepl(\"V\", names(sitesFrame))])\n\n\n################################################################################################################\n\n# need to know the most abundant species per column, for loop because it's easier and I'm short on time\n# sd is not absolutely necessary here\n\nsortedMostAbundant <- list()\nfor (i in 1:length(sitesFrame)) {\n  sortedMostAbundant[[i]] <- sitesFrame[order(sitesFrame[,i], decreasing = T),]\n  sortedMostAbundant[[i]] <- sortedMostAbundant[[i]][,c(length(sortedMostAbundant[[i]]),i)]\n}\n\nsortedMostAbundant <- sortedMostAbundant[-length(sortedMostAbundant)]\n\n# can decide that dominant species together account for 90% of the numbers\n\nchainsaw <- function(x) {\n  # first it needs to calculate the sum of the numbers\n  sumOfNumbers <- sum(x[,2])\n  # then calculate n as in n = sumOfNumbers*domPerc / 100\n  n = sumOfNumbers*90/100\n  # # then count how many elements of x[,2] are needed to go as big as n, where the count is z\n  v <- 0\n  z <- 0\n  for (i in 1:nrow(x)) {\n    if (v < n) {\n      v <- v + x[i,2]\n      z <- z + 1\n    } else {\n      v <- v\n      z <- z\n    }\n  }\n  # # finally subset the original frame x taking the first z counts, which should add up to the closest possible to\n  # # the chosen percentage\n  y <- x[1:z,]\n  return(y)\n  \n}\n\n\ndominantPerc <- lapply(sortedMostAbundant, chainsaw)\n\n\n# from here the most abundant species can be extracted. I hoped the community to be a bit less diverse tbh,\n# in some cases about 20 species account for 90% of the diversity (which is not even that big of a percentage to consider)\n\n###########################################################################################################\n\n# resuming back from the list of data frames per site (listOfSites)\n# need to average 3 by 3. Same strategy as above I reckon\n\n# here I must calculate the grand mean and the grand sd. ominous\n# for the purpose, I split the original frame into 2 though\n\n\nsitesFrameMeans <- sitesFrame[,grepl(\"mean\", names(sitesFrame))]\nsitesFrameVar <- sitesFrame[,grepl(\"V\", names(sitesFrame))]\n\n\nm <- 1:ncol(sitesFrameMeans)\nindYears <- data.frame(matrix(c(m, rep(NA, 3 - ncol(sitesFrameMeans)%%3)), byrow=F, nrow = 3))\nnoNAYears <- sapply(indYears, function(x) all(!is.na(x)))\nindYears <- indYears[, noNAYears]\n\nyearsFrame <- as.data.frame(do.call(cbind, lapply(indYears, function(i) rowMeans(sitesFrameMeans[,i])))) # it seems to be working although I don't know how\n#yearsFrame$Species <- speciesOrDescription\n#colnames(yearsFrame) <- c(years, \"Species\")\n\n# define function to calculate the combined sd according to\n# GSD = sqrt((ESS+TGSS)/N-1)\n# ESS <- (var1*dof1) + (var2*dof2) + ... + (varN*dofN) # where n is the group, i.e. the site A B C, i.e. the column\n# TGSS <- (µ1-GM)^2 * n1 + (µ2-GM)^2 * n2 + ... + (µN-GM)^2 * nN\n\nyearsFrameCheat <- cbind(yearsFrame, yearsFrame, yearsFrame)\ncolumnIndex <- c(1,11,21,2,12,22,3,13,23,4,14,24,5,15,25,6,16,26,7,17,27,8,18,28,9,19,29,10,20,30) # please don't\n\nyearsFrameCheat <- yearsFrameCheat[,columnIndex] \n\nGSDcalculator <- function(x) {\n  ESS <- rowSums(sitesFrameVar[,x]*(length(quadrats)-1)) # so far so good, don't chack again\n  TGSS <- rowSums((sitesFrameMeans[,x]-yearsFrameCheat[,x])^2*length(quadrats)) # faulted SON OF A BITCH WILL MESS THE COLUMNS\n  GSD <- sqrt((ESS+TGSS)/(length(years)-1))\n  return(GSD)  \n}\n\nGSDframe <- as.data.frame(do.call(cbind, lapply(indYears, GSDcalculator))) \n\n# now put species, means and sd together\n\nyearsFrame$Species <- speciesOrDescription\ncolnames(yearsFrame) <- c(years, \"Species\")\n\nGSDframe$Species <- speciesOrDescription\ncolnames(GSDframe) <- c(years, \"Species\")\n\nmeltYears <- melt(yearsFrame, id.vars = \"Species\", variable.name = \"Year\", value.name = \"Mean\" )\nmeltYears$Year <- as.numeric(as.character(meltYears$Year))\nmeltGSD <- melt(GSDframe, id.vars = \"Species\", variable.name = \"Year\", value.name = \"GSD\" )\n\nmeltComplete <- cbind(meltYears, meltGSD$GSD)\n\n# area chart\n\narea <- ggplot(data = meltComplete, aes(x = Year, y = Mean, group = Species, fill = Species))+\n  geom_area()+\n  guides(fill = F)+\n  scale_x_continuous(breaks = seq(5,16,1),\n                     labels = seq(5,16,1),\n                     limits = c(5,16))+\n  scale_y_continuous(limits = c(0,200),\n                     breaks = seq(0,200,50))+\n  theme_bw()+\n  theme(panel.grid.minor = element_blank(), \n        panel.grid.major = element_blank())+\n  theme(plot.title = element_text(size=14, vjust=2))+\n  theme(axis.title.x = element_text(size=10,vjust=-0.5),\n        axis.title.y = element_text(size=10,vjust=0.5))+\n  theme(axis.text.x=element_text(size=10))+\n  theme(axis.text.y=element_text(size=10))\narea\n\n# barchart\n\nbar <- ggplot(data = meltComplete, aes(x = Year, y = Mean, group = Species, fill = Species))+\n  geom_bar(stat = \"identity\")+\n  guides(fill = F)\nbar\n\n\n# all the possible entries are plotted. script needs to be adapted to include only the desired species, i.e. to\n# restrict the analysis to either the most abundant or the complete cases. Keep in mind that this is only the number\n\n\n##############################################################################################\n\n# take the most abundant species from the grand mean and extract the most abundant ones. sticking to \n# 90% of the abundance for now (from 90 to 95 it's almost double the species, many of which are undetermined\n# anyway). Writes a .csv file that can be modified in excel to enter higher taxa (coarser resolution) and \n# functional roles, or other levels of agregation. then it reads that file in again and reorganize the \n# completeFrame object in accordance to the desired criterion\n\nsortedMostAbundant <- list()\nfor (i in 1:length(yearsFrame)) {\n  sortedMostAbundant[[i]] <- yearsFrame[order(yearsFrame[,i], decreasing = T),]\n  sortedMostAbundant[[i]] <- sortedMostAbundant[[i]][,c(length(sortedMostAbundant[[i]]),i)]\n}\n\nsortedMostAbundant <- sortedMostAbundant[-length(sortedMostAbundant)]\n\n# can decide that dominant species together account for 90% of the numbers\n\nchainsaw <- function(x, perc) {\n  # first it needs to calculate the sum of the numbers\n  sumOfNumbers <- sum(x[,2])\n  # then calculate n as in n = sumOfNumbers*domPerc / 100\n  n = sumOfNumbers*perc/100\n  # # then count how many elements of x[,2] are needed to go as big as n, where the count is z\n  v <- 0\n  z <- 0\n  for (i in 1:nrow(x)) {\n    if (v < n) {\n      v <- v + x[i,2]\n      z <- z + 1\n    } else {\n      v <- v\n      z <- z\n    }\n  }\n  # # finally subset the original frame x taking the first z counts, which should add up to the closest possible to\n  # # the chosen percentage\n  y <- x[1:z,]\n  return(y)\n  \n}\n\n\ndominantPerc <- lapply(sortedMostAbundant, chainsaw, 90)\ndominantSpecies <- lapply(dominantPerc, function(x) {\n  x$Year <- rep(names(x[2]), nrow(x))\n  return(x)\n}\n)\n\nspeciesPerc <- abind(dominantSpecies, along = 1)\nspeciesPerc <- as.data.frame(speciesPerc, row.names = seq(1:nrow(speciesPerc)))\ncolnames(speciesPerc) <- c(\"Species\", \"Abundance\", \"Year\")\nspeciesPerc$Abundance <- as.numeric(as.character(speciesPerc$Abundance))\ntoBeDetermined <- levels(factor(speciesPerc$Species))\n\n#write.csv(speciesPerc, \"/home/somros/Documents/R/exploratoryHoga/output/mostAbundant.csv\")\n#write.csv(toBeDetermined, \"/home/somros/Documents/R/exploratoryHoga/output/toBeDetermined.csv\")\n\ncriteria <- read.csv(\"/home/somros/Documents/R/exploratoryHoga/input/criteria.csv\")\n\nhead(meltComplete)\n\n# need to write a function\n\nsubstituteNames <- function(dataFrame, columnNumber) {\n  # starting point is melted frame. function may read it line by line, and for each entry if there is a\n  # corresponding entry in the criteria.csv file then it substitues it with it the corresponding order or\n  # family or in general column. it has to return a dataframe, which can then be split into two for the \n  # respective operations with means and sd and so on\n  dataFrame[1,] <- as.character(dataFrame[1])\n  if (dataFrame[1,] %in% levels(criteria[,2])) {\n    dataFrame[1] <- criteria[grep(dataFrame[1], criteria[,2]),columnNumber]\n  } else {\n    dataFrame[1] <- NA\n  }\n  return(dataFrame)\n}\n\nmeltComplete$Species <- as.character(meltComplete$Species)\n\ntempList <- vector(mode = \"list\", length = nrow(meltComplete))\n\nfor(i in 1:nrow(meltComplete)) {\n  if (meltComplete[i,1] %in% levels(criteria[,2])) {\n    pattern <- meltComplete[i,1]\n    tempList[[i]] <- as.character(criteria[criteria$x == pattern, 3])\n  } else {\n    tempList[[i]] <- NA\n  }\n}\n\n\n\norderVector <- unlist(tempList)\n\nmeltComplete$Order <- orderVector\nmeltComplete <- meltComplete[-1]\nmeltComplete <- meltComplete[complete.cases(meltComplete),]\n\n# now need to sum over the factorized Orders, means as well as sd\n# it needs to be per year you idiot\n\ncombiner <- function(z) {\n  lapply(z, function(x) {\n  yearComb <- x[1,1]\n  meanComb <- sum(x[,2])\n  sdComb <- sqrt(sum(x[,3]^2))\n  orderComb <- x[1,4]\n  y <- data.frame(yearComb, meanComb, sdComb, orderComb)\n  return(y)\n  })\n}\n\n# split apply combine\n\n# order is too specific and this will have to become custom as function\n\nbyOrder <- split(meltComplete, meltComplete$Order)\nbyOrderByYear <- lapply(byOrder, function(x) split(x, x$Year))\nbyOrderTotal <- lapply(byOrderByYear, combiner)\nordersByYear <- lapply(byOrderTotal, function(x) abind(x, along = 1))\ncompleteByOrder <- as.data.frame(abind(ordersByYear, along = 1))\n\n# messed with the classes, need to fix again\n\ncompleteByOrder$meanComb <- as.numeric(as.character(completeByOrder$meanComb))\ncompleteByOrder$sdComb <- as.numeric(as.character(completeByOrder$sdComb))\ncompleteByOrder$yearComb <- as.numeric(as.character(completeByOrder$yearComb))\ncolnames(completeByOrder) <- c(\"Year\", \"Mean\", \"SD\", \"Order\")\nrownames(completeByOrder) <- seq(1, nrow(completeByOrder))\n\n# so far so good. now plotting finally\n\nlibrary(RColorBrewer)\npar(mar = c(0, 4, 0, 0))\ndisplay.brewer.all()\nnOfColors <- length(levels(completeByOrder$Order))\ngetPalette <- colorRampPalette(brewer.pal(11, \"BrBG\"))\n#myPalette <- doublePalette[seq(3,length(doublePalette),1)]\n\narea <- ggplot(data = completeByOrder, aes(x = Year, y = Mean, group = Order, fill = Order))+\n  geom_area()+\n  scale_fill_manual(values = getPalette(nOfColors))+\n  scale_x_continuous(breaks = seq(5,16,1),\n                     labels = seq(5,16,1),\n                     limits = c(5,16))+\n  scale_y_continuous(limits = c(0,180),\n                     breaks = seq(0,180,20))+\n  labs(y=expression(paste(Sponge~density~(n~m^2))))+\n  theme_bw()+\n  theme(panel.grid.minor = element_blank(), \n        panel.grid.major = element_blank())+\n  theme(plot.title = element_text(size=14, vjust=2))+\n  theme(axis.title.x = element_text(size=10,vjust=-0.5),\n        axis.title.y = element_text(size=10,vjust=0.5))+\n  theme(axis.text.x=element_text(size=10))+\n  theme(axis.text.y=element_text(size=10))\narea\n\n# barchart\n\nbar <- ggplot(data = completeByOrder, aes(x = Year, y = Mean, group = Order, fill = Order))+\n  geom_bar(stat = \"identity\")+\n  scale_x_continuous(breaks = seq(5,16,1),\n                     labels = seq(5,16,1),\n                     limits = c(4,17))+\n  scale_y_continuous(limits = c(0,180),\n                     breaks = seq(0,180,20))+\n  scale_fill_manual(values = getPalette(nOfColors))+\n  labs(y=expression(paste(Sponge~density~(n~m^2))))+\n  theme_bw()+\n  theme(panel.grid.minor = element_blank(), \n        panel.grid.major = element_blank())+\n  theme(plot.title = element_text(size=14, vjust=2))+\n  theme(axis.title.x = element_text(size=10,vjust=-0.5),\n        axis.title.y = element_text(size=10,vjust=0.5))+\n  theme(axis.text.x=element_text(size=10))+\n  theme(axis.text.y=element_text(size=10))\nbar\n\n# lineplot\n\nlineplot <- ggplot(data = completeByOrder, \n                   aes(x = Year, y = Mean, group = Order))+\n  geom_line()+\n  geom_point()+\n  guides(fill = F)+\n  geom_errorbar(data = completeByOrder,\n                aes(ymax = completeByOrder$Mean + completeByOrder$SD,\n                    ymin = completeByOrder$Mean - completeByOrder$SD,\n                    width = .2))+\n  scale_x_continuous(breaks = seq(5,16,2),\n                     labels = seq(5,16,2),\n                     limits = c(5,16))+\n  scale_y_continuous(limits = c(-30,100),\n                     breaks = seq(-30,100,20))+\n  labs(y=expression(paste(Sponge~density~(n~m^2))))+\n  theme_bw()+\n  theme(panel.grid.minor = element_blank(), \n        panel.grid.major = element_blank())+\n  theme(plot.title = element_text(size=14, vjust=2))+\n  theme(axis.title.x = element_text(size=10,vjust=-0.5),\n        axis.title.y = element_text(size=10,vjust=0.5))+\n  theme(axis.text.x=element_text(size=10))+\n  theme(axis.text.y=element_text(size=10))+\n  facet_wrap( ~ Order, nrow = 3 )\nlineplot\n\n# ggsave(\"/home/somros/Documents/R/exploratoryHoga/output/pics/spongeAbundanceArea.pdf\", area,\n#        width=5, height=3, useDingbats=T)\n# ggsave(\"/home/somros/Documents/R/exploratoryHoga/output/pics/spongeAbundanceBars.pdf\", bar,\n#        width=5, height=3, useDingbats=T)\n# ggsave(\"/home/somros/Documents/R/exploratoryHoga/output/pics/spongeAbundanceLines.pdf\", lineplot,\n#        width=9, height=10, useDingbats=T)\n\n# calculates the coefficient of variation\n\nhead(completeByOrder)\ncompleteByOrder$CV <- completeByOrder$SD/completeByOrder$Mean\n\n",
    "created" : 1476245016984.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "410322415",
    "id" : "A849220B",
    "lastKnownWriteTime" : 1476829238,
    "last_content_update" : 1476829238148,
    "path" : "//staff/Home/SCIFAC/rovellal/DocumentsRedir/rProjects/hoga/exploratoryHoga/trunk/betterBuoy3.R",
    "project_path" : "betterBuoy3.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}