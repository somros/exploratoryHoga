{
    "collab_server" : "",
    "contents" : "# Sandbox script for a mixture of things, collecting MDS plots, quadrats fate and possibly also the growth\n# model at some point. Most recent script, should be of reference for current analysis.\n\nrequire(abind)\nrequire(MASS)\nrequire(reshape2)\nrequire(ggplot2)\n\n\nsetwd(\"//Staff/Home/SCIFAC/rovellal/DocumentsRedir/Data/Hoga/buoy3\")\nmyData <- read.csv(\"spongeAbundanceQuadrats.csv\")\n\n# turn to numeric immediately\n\nmyData <- myData[c(1:124),]\nmyData <- apply(myData, 2, as.numeric)\nmyData[is.na(myData)] <- 0 # turns NAs in 0, as necessary for Bray-Curtis\nmyData <- as.data.frame(myData)\n\n# definition of the species\n\nspecies <- read.csv(\"//Staff/Home/SCIFAC/rovellal/DocumentsRedir/Data/Hoga/buoy3/speciesKey.csv\")\nspecies[species==\"\" | species==0] <- NA # drop all that is not a name, to be refined though\n\nspeciesOrDescription <- list()\n\nfor (i in 1:nrow(species)) {\n  if (is.na(species[,2][i])==T) {\n    speciesOrDescription[[i]] <- species[,3][i]\n  } else {\n    speciesOrDescription[[i]] <- species[,2][i]\n  }\n}\nspeciesOrDescription <- unlist(speciesOrDescription)\n\n\n# some steps to break down the frame in a list of frames, one per year per site.\n\nnOfQuadrats <- 5\n\nmyData$Species <- speciesOrDescription\n\n# TODO: introduce routine to cut data frames to the species accounting for 90% of the abundance. must be applied\n# to each quadrat and then all the species considered make the subset key for the entire data frame\n\n# we do it with apply. jk lol use a loop apply is slow af anyway\n\n# perc <- 90\n# \n# species <- vector(\"list\", length = ncol(myData)-1)\n# \n# for (k in 2:ncol(myData)) {\n#   dataOrd <- myData[order(myData[,k], decreasing = T),]\n#   # does the math: sum all the entries in one column to get the total\n#   totNum <- sum(dataOrd[,k])\n#   n <- totNum*perc/100\n#   ntmp <- 0\n#   spy <- 0\n#   for (i in 1:nrow(dataOrd)) {\n#     if (ntmp < n) {\n#       ntmp <- ntmp + dataOrd[i,k]\n#       spy <- i\n#     } else {\n#       ntmp <- ntmp\n#       spy <- spy\n#     }\n#   }\n#   species[[k]] <- dataOrd[c(1:spy),1]\n# }\n# \n# # NOTE: using the names of the taxonomic entries instead of numerical indexing means that the levels of the former are fewer\n# # than those of the latter, as the data frame has duplicate entries in the indentification column\n# \n# species <- factor(levels(factor(unlist(lapply(species, as.character)))))\n\n# now subset original data\n\n# subsetData <- myData[myData[,1] %in% species,] # there we go\n\n\n\n\n# if for whatever reason we want to use the entire set of species for the analysis, we can get rid of the above\n# section (this should become a flag). \n# the above routine may be better off if used on the means. That would rule out all the outliers from the\n# single quadrats. The number of species is however half the original amount.\n\n\ndataQuad <- myData[,-1] # remove species for convenience\n\n\n# create vector of indeces for consequent loop (breakage)\n\nindeces <- rep(1:30, each = 5)\n\ndataQuadN <- rbind(indeces, dataQuad)\n\n# split into list depending on the index\n\nnewList <- vector(mode = \"list\", length = length(indeces)/nOfQuadrats)\n\nfor (i in 1:length(newList)) {\n  subsetFrame <- dataQuadN[1,]==i\n  newList[[i]] <- dataQuadN[,subsetFrame]\n}\n\n\n# get rid of the index and make row means (sd later)\n\nnewListMeans <- lapply(newList, function(x) {\n  y <- x[-1,] # gets rid of the \"indeces\" row used for the splitting\n  z <- rowMeans(y)\n  frame <- as.data.frame(z[1:nrow(dataQuad)])\n  colnames(frame) <- paste(\"Mean\", substr(names(x[1,])[1], 2,3), substr(names(x[1,])[1], 5, 5), sep = \"\")\n  return(frame)\n})\n\n\nallMeansTMP <- as.data.frame(abind(newListMeans, along = 2))\n\nallMeans <- cbind(speciesOrDescription, allMeansTMP)\n\n\n\n\n\n\n\n####################  testing phase  ######################\n\n# add the subsetting routine here and see how many species we manage to cut\n\nperc <- 90\n\nspeciesSet <- vector(\"list\", length = ncol(myData)-1)\n\nfor (k in 2:ncol(allMeans)) {\n  dataOrd <- allMeans[order(allMeans[,k], decreasing = T),]\n  # does the math: sum all the entries in one column to get the total\n  totNum <- sum(dataOrd[,k])\n  n <- totNum*perc/100\n  ntmp <- 0\n  spy <- 0\n  for (i in 1:nrow(dataOrd)) {\n    if (ntmp < n) {\n      ntmp <- ntmp + dataOrd[i,k]\n      spy <- i\n    } else {\n      ntmp <- ntmp\n      spy <- spy\n    }\n  }\n  speciesSet[[k]] <- dataOrd[c(1:spy),1]\n}\n\n# NOTE: using the names of the taxonomic entries instead of numerical indexing means that the levels of the former are fewer\n# than those of the latter, as the data frame has duplicate entries in the indentification column\n\nspeciesSet <- factor(levels(factor(unlist(lapply(speciesSet, as.character)))))\n\n#now subset original data\n\nsubsetData <- allMeans[allMeans[,1] %in% speciesSet,]  # there we go\n\n\n# comment: this sucks because the original identification is approximate and full of duplicates stemming from typos.\n# this must be redone with a decent input file, that requires some work. Also all the descriptions must be pooled\n# as undetermined. this removes the original \"species or description\" routine, as it will be done in excel. IN any case\n# there don't seem to be too many duplicates, it's more about a huge quantity of approximate descriptions.\n\n# way out is calling undetermined all that is not a species AT THIS STAGE, because if done at the beginning then Undetermined\n# dominate the community and we miss the whole point of getting rid of not abundant species. easiest way is excel\n\nwrite.csv(subsetData$speciesOrDescription, \"subsetOfSpecies.csv\")\n\nstring <- read.csv(\"//Staff/Home/SCIFAC/rovellal/DocumentsRedir/Data/Hoga/buoy3/speciesString.csv\", header = F)[,1]\n\n# get the levels\n\nfinalSpecies <- levels(factor(string))\n\n# to do now is to substitute the first column with the appropriate entry\n\nsubsetData$speciesOrDescription <- as.character(subsetData$speciesOrDescription)\n\nfor (i in 1:nrow(subsetData)) {\n  if (subsetData[i,1] %in% finalSpecies) {\n    subsetData[i,1] <- subsetData[i,1]\n  } else {\n    subsetData[i,1] <- \"Undetermined\"\n  }\n}\n\nsubsetData$speciesOrDescription <- as.factor(subsetData$speciesOrDescription)\n\n# ad hoc correction for pseudocertaina (which is even spelled wrong actually)\n\nsubsetData[subsetData$speciesOrDescription == \"Pseudocertaina sp. ?\",1] <- \"Pseudocertaina sp.\"\nsubsetData$speciesOrDescription <- droplevels(subsetData$speciesOrDescription)\n\n# now need to split and sum. is this legit with the means though? there isn't really any other solution anyway, as\n# we need to choose between this \"inaccurate\" method and keeping a lot of species in the routine that are not abundant\n\n# split-apply-combine routine\n\nsplitFrame <- split(subsetData, subsetData$speciesOrDescription)\nsplitFrameSums <- lapply(splitFrame, function(x) {\n  y <- x[,-1]\n  z <- colSums(y)\n  return(c(as.character(x[1,1]), z)) # turns all into character, annoyingly enough\n}\n)\nframeSums <- abind(splitFrameSums, along = 0)\n\nframeSums <- cbind.data.frame(factor(frameSums[,1]), apply(frameSums[,-1], 2, as.numeric))\n\n# after all the workarounds it is still full of typos, but especially the undetermined make up for a big chunk of the community.\n# MDS is going to be very different and fundamentally wrong because of the heavy pooling. not recommended for MDS!!\n\n#########################################################################################\n\n\n\n# from here on the script must take different paths. you did it wrong for the quadrats fate though.\n\n# getting messy. plot averages now. Transposition should be enough. In all of this we completely ignore the \n# uncertainty and this is not OKAY\n\ntransDatatmp <- as.data.frame(t(frameSums))\ntransDatatmp <- transDatatmp[-1,]\ntransData <- as.data.frame(apply(transDatatmp, 2, function(x) as.numeric(as.character(x))))\n\nrownames(transData) <- rownames(transDatatmp)\n\ntransData$Total <- rowSums(transData) \n\nID <- rownames(transData)\ntransData$Year <- as.numeric(substr(ID, 5, 6))\ntransData$Site <- substr(ID, nchar(ID), nchar(ID))\n\n# need to melt here\n\nmeltData <- melt(transData, id.vars = c(\"Year\", \"Site\"))\n\nmeanPlot <- ggplot(data = meltData[meltData$variable != \"Total\",], aes(x = Year, y = value, color = variable))+\n  geom_line()+\n  geom_point()+\n  #scale_y_continuous(trans = \"log10\")+\n  theme_bw()+\n  facet_grid(.~Site)\nmeanPlot\n\nggsave(\"//Staff/Home/SCIFAC/rovellal/DocumentsRedir/Wellington/words/latex/hogaExploratory/Pics/meanPlot.pdf\",\n       meanPlot, useDingbats = T) \n\n\n\n\n\n\n\n###### ATTENTION!!! ######\n\n# MDS routine is extremely biased by the pooling of undetermined species. I strongly advise against using the pooled taxonomy\n# for this analysis, as the information is WRONG.\n# mds ROUTINE MUST RESUME THE MEAN DATAFRAME FROM THE BEGINNING\n\n# transform in log(x+1). we can debate wether we want to have this done here or earlier. as a rule of thumb,\n# the earlier the better. Need to investigate the sensitivity to this of the MDS plot though, prepare 2 versions\n\nallMeansTrans <- log10(allMeansTMP+1)\n\n\n# now get a list out of this, each element of a list is a time series with the means for a site. One element per site\n# i.e. 3 elements\n\nsites <- levels(factor(unlist(lapply(names(allMeansTrans), function(x) substr(x, nchar(x), nchar(x))))))\n\nsitesList <- vector(mode = \"list\", length = length(sites))\n\n\nfor(i in sites) {\n  sitesList[[match(i, sites)]] <- allMeansTrans[,grepl(i, names(allMeansTrans))]\n}\n\n# now the similarity index must be calculated\n\nmatrixList <- list()\n\nfor (s in 1:length(sitesList)) {\n  \n  S <- sitesList[[s]]\n  \n  grandBC <- list()\n  \n  for (i in 1:length(S)) {\n    BC <- vector(mode = \"logical\", length = length(S))\n    for (j in 1:length(S)) {\n      reduced <- S[,c(i,j)]\n      BCpartial <- apply(reduced, 1, function(x) {\n        numBC <- 2*min(x[1], x[2])\n        denBC <- x[1]+x[2]\n        metrics <- c(numBC, denBC)\n      })\n      BC[j] <- rowSums(BCpartial)[1]/rowSums(BCpartial)[2]\n    }\n    grandBC[[i]] <- BC\n  } # minchia che culo\n  \n  kekes <- abind(grandBC, along = 0)\n  colnames(kekes) <- names(S)\n  rownames(kekes) <- names(kekes)\n  matrixList[[s]] <- kekes\n}\n\n\n# now MDS plots how the hell do they work\n\n# turn into bloody dissimilarity\n\ndissList <- lapply(matrixList, function(x) 1-x)\n\nfitList <- lapply(dissList, function(x) {\n  fit <- isoMDS(x, k = 2)\n  y <- fit$points[,1]\n  z <- fit$points[,2]\n  yzFrame <- data.frame(y,z)\n  yzFrame$Names <- names(x[1,])\n  return(yzFrame)\n}\n)\n\n\nplot(fitList[[3]][,1], fitList[[3]][,2], xlab=\"Coordinate 1\", ylab=\"Coordinate 2\", \n     main=\"Nonmetric MDS\", type=\"n\")\ntext(fitList[[3]][,1], fitList[[3]][,2], labels = names(dissList[[1]][1,]), cex=.7)\n\n# please turn this to ggplot for the sake of decency\n\nallFrames <- as.data.frame(abind(fitList, along = 1))\nallFrames$y <- as.numeric(as.character(allFrames$y))\nallFrames$z <- as.numeric(as.character(allFrames$z))\nallFrames$Names <- as.character(allFrames$Names) # for substr\nallFrames$Site <- rep(sites, each = 10)\n# add year for colour key\n\nallFrames$Year <- rep(NA, nrow(allFrames))\n\nfor (i in 1:nrow(allFrames)) {\n  allFrames$Year[i] <- paste(\"20\", substr(allFrames$Names[i], \n                                          (nchar(allFrames$Names[i])-2), \n                                          (nchar(allFrames$Names[i])-1)),\n                             sep = \"\")\n}\n\n# plot\n\nMDSplotYears <- ggplot(data = allFrames, aes(x = y, y = z, group = Site, color = Year))+\n  geom_text(aes(label = Year, color = Year))+\n  theme_bw()+\n  facet_grid(.~Site)\nMDSplotYears\n\n\n\n# Note: MDS plot here is different because it's calulated on the entire community, and not on the subsetted\n# number of taxonomic unites forming the 90% of the abundance. This is because in this script the subsetting\n# routine is carried out on the means, in order to reduce (supposedly) the number of taxonomic units to\n# a smaller number. Should be flagged and transformed in binary routine depending on the desired analysis",
    "created" : 1476830386134.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2624938426",
    "id" : "21FBFE25",
    "lastKnownWriteTime" : 1477360305,
    "last_content_update" : 1477360305916,
    "path" : "//staff/Home/SCIFAC/rovellal/DocumentsRedir/rProjects/hoga/exploratoryHoga/trunk/sandBox.R",
    "project_path" : "sandBox.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}